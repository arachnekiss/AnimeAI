# ğŸ­ AnimeRig AI - Desktop Character Animation System

> **Native Desktop Application for Real-time AI Character Animation and Interaction**

[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![Python](https://img.shields.io/badge/Python-3.8+-blue.svg)](https://python.org/)
[![Qt](https://img.shields.io/badge/Qt-6.0+-green.svg)](https://qt.io/)
[![C++](https://img.shields.io/badge/C++-17-red.svg)](https://isocpp.org/)
[![Go](https://img.shields.io/badge/Go-1.23+-cyan.svg)](https://golang.org/)

## ğŸŒŸ Overview

AnimeRig AIëŠ” ë‹¨ì¼ ì´ë¯¸ì§€ì—ì„œ ì‹¤ì‹œê°„ ìºë¦­í„° ì• ë‹ˆë©”ì´ì…˜ì„ ìƒì„±í•˜ëŠ” ë„¤ì´í‹°ë¸Œ ë°ìŠ¤í¬í†± ì• í”Œë¦¬ì¼€ì´ì…˜ì…ë‹ˆë‹¤. Python Qt6 ì¸í„°í˜ì´ìŠ¤, C++ ë Œë”ë§ ì—”ì§„, Go ë°±ì—”ë“œ ì„œë¹„ìŠ¤ë¥¼ ê²°í•©í•˜ì—¬ ê³ ì„±ëŠ¥ AI ê¸°ë°˜ ìºë¦­í„° ì• ë‹ˆë©”ì´ì…˜ ì‹œìŠ¤í…œì„ ì œê³µí•©ë‹ˆë‹¤.

## âœ¨ ì£¼ìš” ê¸°ëŠ¥

- ğŸ–¼ï¸ **Single Image to Rig**: ë‹¨ì¼ ì´ë¯¸ì§€ì—ì„œ ìë™ ìºë¦­í„° ë¦¬ê¹…
- ğŸ­ **Real-time Animation**: ì‹¤ì‹œê°„ í‘œì • ë° ì œìŠ¤ì²˜ ì• ë‹ˆë©”ì´ì…˜
- ğŸ—£ï¸ **AI Chat Integration**: LLM ê¸°ë°˜ ì§€ëŠ¥í˜• ìºë¦­í„° ëŒ€í™”
- ğŸ¨ **3D Rendering**: OpenGL ê¸°ë°˜ ê³ ì„±ëŠ¥ 3D ë Œë”ë§
- ğŸµ **Voice Synthesis**: ê°ì • ê¸°ë°˜ ìŒì„± í•©ì„±
- ğŸ“¹ **Export Capabilities**: ì• ë‹ˆë©”ì´ì…˜ ë…¹í™” ë° ë‚´ë³´ë‚´ê¸°

## ğŸ—ï¸ ì‹œìŠ¤í…œ ì•„í‚¤í…ì²˜

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Frontend      â”‚    â”‚   C++ Engine    â”‚    â”‚   Go Backend    â”‚
â”‚   (Python Qt6) â”‚â—„â”€â”€â–ºâ”‚   (OpenGL)      â”‚â—„â”€â”€â–ºâ”‚   (WebSocket)   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                       â”‚                       â”‚
         â”‚                       â”‚                       â”‚
    â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”            â”Œâ”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ Desktop â”‚            â”‚ 3D Render â”‚         â”‚ LLM Service   â”‚
    â”‚   UI    â”‚            â”‚  Engine   â”‚         â”‚ & AI Models   â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ› ï¸ ê¸°ìˆ  ìŠ¤íƒ

- **Frontend**: Python 3.8+, PyQt6, OpenCV, MediaPipe
- **Engine**: C++17, OpenGL, GLFW, Eigen3, Assimp
- **Backend**: Go 1.23+, Gin, WebSocket, AI/LLM APIs
- **AI/ML**: TensorFlow, PyTorch, Hugging Face Transformers

## ğŸš€ ë¹ ë¥¸ ì‹œì‘

### 1. ì‹œìŠ¤í…œ ìš”êµ¬ì‚¬í•­

```bash
# Ubuntu/Debian
sudo apt update && sudo apt install -y \
    python3 python3-pip python3-venv \
    build-essential cmake \
    libgl1-mesa-dev libglu1-mesa-dev \
    libglfw3-dev libglew-dev \
    libeigen3-dev libassimp-dev \
    qt6-base-dev \
    golang-go

# macOS (Homebrew)
brew install python qt cmake eigen glfw glew assimp go

# Windows (see detailed instructions in docs/)
```

### 2. ì„¤ì¹˜ ë° ë¹Œë“œ

```bash
# ì €ì¥ì†Œ í´ë¡ 
git clone https://github.com/your-username/AnimeAI.git
cd AnimeAI/animerig-ai

# í™˜ê²½ ì„¤ì • ë³µì‚¬
cp .env.example .env
# .env íŒŒì¼ì„ í¸ì§‘í•˜ì—¬ API í‚¤ ë“±ì„ ì„¤ì •

# ì „ì²´ ë¹Œë“œ (ìë™ ì˜ì¡´ì„± ì„¤ì¹˜ í¬í•¨)
./scripts/build.sh

# ì• í”Œë¦¬ì¼€ì´ì…˜ ì‹¤í–‰
./scripts/run.sh
```

### 3. ê°œë°œ ëª¨ë“œ ì‹¤í–‰

```bash
# Python ê°€ìƒí™˜ê²½ í™œì„±í™”
source venv/bin/activate

# ê° ì»´í¬ë„ŒíŠ¸ ê°œë³„ ì‹¤í–‰
# 1. Go ë°±ì—”ë“œ ì„œë²„
cd backend && go run cmd/server/main.go &

# 2. Python ë°ìŠ¤í¬í†± ì•±
cd frontend/desktop && python main.py
```

## ğŸ“ í”„ë¡œì íŠ¸ êµ¬ì¡°

```
animerig-ai/
â”œâ”€â”€ ai/                    # AI/ML ëª¨ë¸ ë° íŒŒì´í”„ë¼ì¸
â”‚   â”œâ”€â”€ emotion_engine/    # ê°ì • ë¶„ì„ ì—”ì§„
â”‚   â”œâ”€â”€ image_to_rig/      # ì´ë¯¸ì§€-ë¦¬ê·¸ ë³€í™˜
â”‚   â”œâ”€â”€ animation_synthesis/ # ì• ë‹ˆë©”ì´ì…˜ ìƒì„±
â”‚   â””â”€â”€ voice_synthesis/   # ìŒì„± í•©ì„±
â”œâ”€â”€ backend/               # Go ë°±ì—”ë“œ ì„œë¹„ìŠ¤
â”‚   â”œâ”€â”€ cmd/server/        # ë©”ì¸ ì„œë²„
â”‚   â””â”€â”€ internal/          # ë‚´ë¶€ íŒ¨í‚¤ì§€ë“¤
â”œâ”€â”€ engine/                # C++ ë Œë”ë§ ì—”ì§„
â”‚   â”œâ”€â”€ src/               # C++ ì†ŒìŠ¤ì½”ë“œ
â”‚   â”œâ”€â”€ include/           # í—¤ë” íŒŒì¼
â”‚   â””â”€â”€ python_bindings/   # Python ë°”ì¸ë”©
â”œâ”€â”€ frontend/              # Python Qt6 ë°ìŠ¤í¬í†± ì•±
â”‚   â””â”€â”€ desktop/           # ë©”ì¸ ë°ìŠ¤í¬í†± ì¸í„°í˜ì´ìŠ¤
â”œâ”€â”€ models/                # ì‚¬ì „ í›ˆë ¨ëœ AI ëª¨ë¸
â”œâ”€â”€ scripts/               # ë¹Œë“œ ë° ì‹¤í–‰ ìŠ¤í¬ë¦½íŠ¸
â””â”€â”€ docs/                  # ë¬¸ì„œ
```

## ğŸ”§ í™˜ê²½ ì„¤ì •

`.env` íŒŒì¼ ì„¤ì •:

```env
# AI ì„œë¹„ìŠ¤ API í‚¤
OPENAI_API_KEY=your_openai_api_key
HUGGINGFACE_TOKEN=your_hf_token

# ì„œë²„ ì„¤ì •
GO_SERVER_PORT=8080
WEBSOCKET_PORT=8081

# ëª¨ë¸ ê²½ë¡œ
MODELS_PATH=./models
ASSETS_PATH=./assets

# ë Œë”ë§ ì„¤ì •
RENDER_WIDTH=1920
RENDER_HEIGHT=1080
FPS=60
```

## ğŸ® ì‚¬ìš©ë²•

1. **ì• í”Œë¦¬ì¼€ì´ì…˜ ì‹œì‘**: `./scripts/run.sh` ì‹¤í–‰
2. **ìºë¦­í„° ë¡œë“œ**: ì´ë¯¸ì§€ íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì—¬ ìë™ ë¦¬ê¹…
3. **ì‹¤ì‹œê°„ ì±„íŒ…**: AI ìºë¦­í„°ì™€ ëŒ€í™”í•˜ë©° ë°˜ì‘ í™•ì¸
4. **ì• ë‹ˆë©”ì´ì…˜ ì œì–´**: ìˆ˜ë™ ì œìŠ¤ì²˜ ë° í‘œì • ì¡°ì •
5. **ë…¹í™” ë° ë‚´ë³´ë‚´ê¸°**: ì• ë‹ˆë©”ì´ì…˜ì„ ë¹„ë””ì˜¤ë¡œ ì €ì¥

## ğŸ§ª í…ŒìŠ¤íŠ¸

```bash
# ì „ì²´ ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸
./scripts/test.sh

# ê°œë³„ ì»´í¬ë„ŒíŠ¸ í…ŒìŠ¤íŠ¸
cd backend && go test ./...
cd frontend && python -m pytest
cd engine && make test
```

## ğŸ“– ë¬¸ì„œ

- [AI Character Engine Guide](docs/AI_CHARACTER_ENGINE.md)
- [Deployment Guide](docs/DEPLOYMENT.md)
- [API Documentation](docs/API.md)
- [Development Guide](docs/DEVELOPMENT.md)

## ğŸ¤ ê¸°ì—¬í•˜ê¸°

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/amazing-feature`)
3. Commit your changes (`git commit -m 'Add amazing feature'`)
4. Push to the branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

## ğŸ“„ ë¼ì´ì„ ìŠ¤

ì´ í”„ë¡œì íŠ¸ëŠ” MIT ë¼ì´ì„ ìŠ¤ í•˜ì— ìˆìŠµë‹ˆë‹¤. ìì„¸í•œ ë‚´ìš©ì€ [LICENSE](LICENSE) íŒŒì¼ì„ ì°¸ì¡°í•˜ì„¸ìš”.

## ğŸ™ ê°ì‚¬ì˜ ë§

- OpenAI GPT ëª¨ë¸
- MediaPipe Face Detection
- Qt Framework
- OpenGL Community
- Go Community

## ğŸ“ ì§€ì›

- ğŸ› Issues: [GitHub Issues](https://github.com/your-username/AnimeAI/issues)
- ğŸ’¬ Discussions: [GitHub Discussions](https://github.com/your-username/AnimeAI/discussions)
- ğŸ“§ Email: support@animerig-ai.com

---

**Made with â¤ï¸ for the AI Animation Community**
=======
<<<<<<< HEAD
# ğŸ­ AI Character Animation Engine

> **Production-ready AI Character Animation Engine with Real-time Expression Mirroring and Interactive Chat**

## ğŸŒŸ **[ğŸš€ LIVE DEMO](https://anime-ai-character-demo.surge.sh)** ğŸŒŸ
*Experience the full interactive demo with AI character generation, real-time animations, and recording capabilities*

[![Deploy on Replit](https://replit.com/badge/github/YOUR_USERNAME/ai-character-engine)](https://replit.com/@YOUR_USERNAME/ai-character-engine)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![TypeScript](https://img.shields.io/badge/TypeScript-007ACC?logo=typescript&logoColor=white)](https://typescriptlang.org/)
[![React](https://img.shields.io/badge/React-20232A?logo=react&logoColor=61DAFB)](https://reactjs.org/)Character Engine

> **Production-ready AI Character Animation Engine with Real-time Expression Mirroring and Interactive Chat**

[![Deploy on Replit](https://replit.com/badge/github/YOUR_USERNAME/ai-character-engine)](https://replit.com/@YOUR_USERNAME/ai-character-engine)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![TypeScript](https://img.shields.io/badge/TypeScript-007ACC?logo=typescript&logoColor=white)](https://typescriptlang.org/)
[![React](https://img.shields.io/badge/React-20232A?logo=react&logoColor=61DAFB)](https://reactjs.org/)

## âœ¨ Features

### ğŸ¯ Core Features
- **Real-time Character Animation** - 60 FPS GPU-accelerated rendering
- **AI-Powered Conversations** - ChatGPT-like interface with living characters
- **Expression Mirroring** - Camera-based facial expression detection and character sync
- **Emotional Voice Synthesis** - AI voice generation with emotional context
- **Character Generation** - Create animated characters from user images
- **Progressive Web App** - Full PWA support with offline capabilities

### ğŸš€ Advanced Features
- **Physics Simulation** - Realistic hair and cloth dynamics
- **Multi-view Rendering** - 360Â° character rotation support
- **Performance Monitoring** - Real-time FPS and memory tracking
- **Voice Input/Output** - Speech-to-text and text-to-speech integration
- **Responsive Design** - Optimized for desktop, tablet, and mobile
- **WebSocket Real-time** - Live synchronization and multiplayer support

## ğŸ® Live Demo

ğŸŒ **[Try the Live Demo](https://ai-character-engine.repl.co)**

### UI Showcase States
1. **Main Interface** - Default character interaction view
2. **User Typing** - Character reacting to user input
3. **Voice Input** - Active voice recording with visualization
4. **Emotional States** - Different character emotions (happy, sad, surprised, etc.)
5. **Performance Monitor** - Real-time debugging tools
6. **Settings Panel** - Comprehensive customization options
7. **Character Creator** - AI-powered character generation
8. **Mobile View** - Responsive mobile interface

## ğŸš€ Quick Start

### 1. Clone & Install
```bash
git clone https://github.com/YOUR_USERNAME/ai-character-engine.git
cd ai-character-engine
npm install
```

### 2. Environment Setup
```bash
cp .env.example .env
# Edit .env with your API keys
```

### 3. Required API Keys
```env
REACT_APP_OPENAI_API_KEY=your_openai_api_key_here
REACT_APP_GPT_MODEL=gpt-4.1
REACT_APP_IMAGE_MODEL=gpt-image-1
REACT_APP_VOICE_MODEL=gpt-4o-mini-tts
```

### 4. Development
```bash
npm run dev
# Frontend: http://localhost:5173
# Backend: http://localhost:3001
```

### 5. Production Build
```bash
npm run build:production
npm run start:production
```

## ğŸŒ Replit Deployment

### One-Click Deploy
1. **Fork Repository** on GitHub
2. **Import to Replit** from your GitHub repo
3. **Add Secrets** in Replit's environment
4. **Click Run** - Your app is live!

### Manual Deployment Steps
```bash
# 1. Push to GitHub
git add .
git commit -m "feat: Ready for Replit deployment"
git push origin main

# 2. Import to Replit
# - Go to replit.com
# - Click "Create Repl"
# - Select "Import from GitHub"
# - Enter your repo URL

# 3. Configure Environment
# Add these secrets in Replit:
OPENAI_API_KEY=your_key_here
NODE_ENV=production
PORT=3000

# 4. Deploy
npm run deploy:replit
```

For complete documentation, visit our [GitHub repository](https://github.com/YOUR_USERNAME/ai-character-engine).
=======
# AnimeRig AI - Native Desktop Application

<div align="center">
  <img src="assets/images/start_character.png" alt="AnimeRig AI" width="200"/>
  
  **Real-time Character Animation from Single Images**
  
  [![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
  [![Python 3.8+](https://img.shields.io/badge/python-3.8+-blue.svg)](https://www.python.org/downloads/)
  [![Go 1.21+](https://img.shields.io/badge/go-1.21+-00ADD8.svg)](https://golang.org/dl/)
  [![C++17](https://img.shields.io/badge/C++-17-blue.svg)](https://en.cppreference.com/w/cpp/17)
</div>

## Overview

AnimeRig AI is a powerful native desktop application that brings static character images to life through real-time animation, emotion simulation, and AI-powered conversation. Built with a multi-language architecture combining Python for AI/ML, C++ for high-performance rendering, and Go for backend services.

### Key Features

ğŸ­ **Real-time Character Animation**
- Convert single images into animated 3D characters
- Facial expression control with emotion mapping
- Natural breathing and blinking animations
- Gesture recognition and response

ğŸ§  **AI-Powered Intelligence**
- Character conversation using large language models
- Emotion detection and responsive animations
- Personality adaptation over time
- Voice synthesis integration (planned)

âš¡ **High-Performance Rendering**
- C++ OpenGL rendering engine
- Physics simulation for hair and clothing
- 60 FPS real-time animation
- GPU acceleration support

ğŸ¨ **Advanced Character Control**
- Detailed finger and hand control
- Facial expression blending
- Custom animation creation
- Physics-based secondary motion

## Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Python Qt6   â”‚    â”‚   C++ Engine    â”‚    â”‚   Go Backend    â”‚
â”‚   Desktop UI    â”‚â—„â”€â”€â–ºâ”‚   Rendering     â”‚â—„â”€â”€â–ºâ”‚   API Server    â”‚
â”‚                 â”‚    â”‚   Animation     â”‚    â”‚   WebSockets    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                       â”‚                       â”‚
         â–¼                       â–¼                       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   AI Pipeline   â”‚    â”‚   Physics Sim   â”‚    â”‚   LLM Client    â”‚
â”‚  Imageâ†’3Dâ†’Rig   â”‚    â”‚  Hair/Clothing  â”‚    â”‚  Conversation   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Quick Start

### Prerequisites

- **Python 3.8+** with pip
- **Go 1.21+**
- **C++ compiler** (GCC 9+ or Clang 10+)
- **CMake 3.16+**
- **Qt6** development libraries
- **OpenGL** support

### Installation

1. **Clone the repository**
   ```bash
   git clone https://github.com/yourusername/animerig-ai.git
   cd animerig-ai
   ```

2. **Run the build script**
   ```bash
   # Install system dependencies (Ubuntu/Debian)
   ./scripts/build.sh --install-system
   
   # Or build without system packages
   ./scripts/build.sh
   ```

3. **Configure environment**
   ```bash
   cp .env.example .env
   # Edit .env with your settings (e.g., OpenAI API key)
   ```

4. **Launch the application**
   ```bash
   ./scripts/run.sh
   ```

### Manual Build (Advanced)

<details>
<summary>Click to expand manual build instructions</summary>

#### 1. Setup Python Environment
```bash
python3 -m venv venv
source venv/bin/activate
pip install -r requirements.txt
```

#### 2. Build C++ Engine
```bash
cd engine
mkdir build && cd build
cmake .. -DCMAKE_BUILD_TYPE=Release -DBUILD_PYTHON_BINDINGS=ON
make -j$(nproc)
cd ../..
```

#### 3. Build Go Backend
```bash
cd backend
go mod tidy
go build -o bin/animerig-server ./cmd/server
cd ..
```

#### 4. Run Components
```bash
# Start backend
./backend/bin/animerig-server &

# Start frontend
source venv/bin/activate
cd frontend/desktop
python3 main.py
```

</details>

## Usage

### Loading a Character

1. Click **File â†’ Load Character Image**
2. Select an image file (PNG, JPG, etc.)
3. Wait for AI processing to complete
4. Your character is now ready for animation!

### Controlling Emotions

Use the **Controls** tab to adjust:
- **Happiness, Sadness, Anger** - Emotional states
- **Surprise, Fear** - Reactive emotions
- **Custom Animations** - Wave, nod, point, etc.

### Chat Interaction

1. Switch to the **Chat** tab
2. Type messages to your character
3. The AI will respond with appropriate animations and text
4. Emotions and gestures adapt to conversation context

### Advanced Features

- **Physics Controls** - Toggle hair/clothing physics
- **Animation Blending** - Smooth transitions between states
- **Custom Rigging** - Import your own 3D models
- **Performance Tuning** - Adjust FPS and quality settings

## Development

### Project Structure

```
animerig-ai/
â”œâ”€â”€ ai/                     # Python AI/ML pipeline
â”‚   â”œâ”€â”€ image_to_rig/      # Imageâ†’3D conversion
â”‚   â”œâ”€â”€ animation_synthesis/ # Motion generation
â”‚   â””â”€â”€ emotion_engine/     # Emotion processing
â”œâ”€â”€ backend/               # Go server & API
â”‚   â”œâ”€â”€ cmd/server/        # Main server application
â”‚   â””â”€â”€ internal/          # Internal packages
â”œâ”€â”€ engine/                # C++ rendering engine
â”‚   â”œâ”€â”€ src/               # Source code
â”‚   â””â”€â”€ include/           # Header files
â”œâ”€â”€ frontend/              # Python Qt6 desktop UI
â”‚   â””â”€â”€ desktop/           # Main application
â”œâ”€â”€ models/                # AI model storage
â”œâ”€â”€ assets/                # Images, icons, etc.
â””â”€â”€ scripts/               # Build & run scripts
```

### Contributing

1. Fork the repository
2. Create a feature branch
3. Make your changes
4. Add tests if applicable
5. Submit a pull request

### Running Tests

```bash
# Python tests
python -m pytest tests/

# Go tests
cd backend && go test ./...

# C++ tests (if enabled)
cd engine/build && make test
```

## Configuration

### Environment Variables

Key settings in `.env`:

- `OPENAI_API_KEY` - For AI conversation features
- `RENDER_WIDTH/HEIGHT` - Output resolution
- `USE_GPU` - Enable GPU acceleration
- `LOG_LEVEL` - Debugging verbosity

### Performance Tuning

- **High-end systems**: Increase `MAX_FPS`, enable all physics
- **Low-end systems**: Reduce resolution, disable complex physics
- **GPU acceleration**: Ensure proper CUDA/OpenCL setup

## Troubleshooting

### Common Issues

**Build fails with missing dependencies**
```bash
# Ubuntu/Debian
sudo apt-get install build-essential cmake libgl1-mesa-dev libglfw3-dev

# macOS
brew install cmake glfw glew eigen assimp

# Windows
# Use vcpkg or install manually
```

**Python modules not found**
```bash
# Ensure virtual environment is activated
source venv/bin/activate
pip install -r requirements.txt
```

**OpenGL errors**
```bash
# Check GPU drivers are installed
glxinfo | grep "direct rendering"

# For headless systems, use software rendering
export LIBGL_ALWAYS_SOFTWARE=1
```

**Performance issues**
- Reduce render resolution in settings
- Disable physics simulation
- Check GPU utilization with `nvidia-smi`

### Getting Help

- ğŸ“– Check the [Documentation](docs/)
- ğŸ› Report bugs in [Issues](https://github.com/yourusername/animerig-ai/issues)
- ğŸ’¬ Join our [Discord](https://discord.gg/animerig) community
- ğŸ“§ Email support: support@animerig.ai

## Roadmap

### Version 1.1 (Q3 2024)
- [ ] Voice synthesis integration
- [ ] Real-time lip sync
- [ ] Custom model import
- [ ] Animation timeline editor

### Version 1.2 (Q4 2024)
- [ ] Multi-character scenes
- [ ] VRM format support
- [ ] Live streaming integration
- [ ] Mobile companion app

### Version 2.0 (2025)
- [ ] VR/AR support
- [ ] Real-time ray tracing
- [ ] Advanced AI personalities
- [ ] Cloud model hosting

## License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## Acknowledgments

- **MediaPipe** - Pose detection and face analysis
- **OpenAI** - Language model integration
- **Qt6** - Cross-platform GUI framework
- **OpenGL** - 3D graphics rendering
- **Eigen** - Linear algebra library
- **Assimp** - 3D model loading

---

<div align="center">
  <strong>Made with â¤ï¸ by the AnimeRig AI team</strong>
  
  [Website](https://animerig.ai) â€¢ [Documentation](docs/) â€¢ [Discord](https://discord.gg/animerig)
</div>
>>>>>>> eb1edbf (m)
>>>>>>> f9640ea7918268475a152689cc56f391200d9025
